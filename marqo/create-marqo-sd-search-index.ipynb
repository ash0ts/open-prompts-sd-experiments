{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e09e3-96cd-42b6-a57e-b4122a62d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/marqo-ai/marqo\n",
    "# https://marqo.pages.dev/End-to-End%20Examples/streamlit_demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b4662-db9f-4811-8f46-92fea38d4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the marqo docker container to read files from local os. For more info on this please visit this link.\n",
    "# https://github.com/marqo-ai/marqo/issues/35\n",
    "# python3 -m http.server 8222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c60e4-4210-4202-8157-7672dfc4be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo chmod 666 /var/run/docker.sock\n",
    "# sudo docker rm -f marqo;docker run --name marqo -it --privileged -p 8882:8882 --add-host host.docker.internal:host-gateway marqoai/marqo:0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c39a5f-840d-489a-b671-17a0c41eab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb\n",
    "!pip install marqo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad3c08-2499-4165-9836-acf32f70ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b633a-a3d3-49e6-af2e-f2b368ef797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"krea-open-prompts\"\n",
    "run_name = \"insert-open-prompts-sd-marqo\"\n",
    "tags = [\"download\", \"stable_diffusion\", \"insert\", \"marqo\"]\n",
    "_config = {\n",
    "    # option of \"prompts\" or \"sample_prompts\"\n",
    "    \"dataset\": \"sample_prompts\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23ab8a-1544-499b-b218-c41343d2ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=project_name, name=run_name, tags=tags, config=_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d435bf-3346-4ce7-8e7a-1fed72217427",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = run.config\n",
    "dataset_name = config['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fabef9-1053-484e-81ce-339f4d81f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = run.use_artifact(f'{dataset_name}:latest', type='processed_data').download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793863db-8f4a-4a08-a37c-dd737be9e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e299bb2-1d2e-4639-a71e-e72dd58bc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(dataset_path, f\"{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04b20b-7935-42bf-a6e8-52199926c0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcb0d9-416b-46a1-abc5-e5c6ed32a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2362116-74c4-4cca-bb0a-1dad0e17ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: better way to prepend artifact path\n",
    "df[\"local_image_location\"] = str(dataset_path) + \"/\" + dataset_name + \"/\" + df[\"local_image_location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cc5b1-a881-44d8-8265-9e4438dcdcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional prepend for marqo\n",
    "df[\"local_image_location\"] = \"http://host.docker.internal:8222/\" + df[\"local_image_location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79baf54e-8753-4612-9ae1-a244d3b13cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"local_image_location\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c68f08-449f-4d03-8b73-b1da87cd81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c27c9-2e48-4a31-aeee-e1554b2e4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03a0d4-5386-4d82-9caf-5bb55fa06822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69ee38-0f8f-453d-9827-511605e4804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e7ae1-0311-434c-8978-75a70503474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marqo import Client\n",
    "from marqo.errors import MarqoApiError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebf936-643b-43ce-b511-83e0e483a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "marqo_settings = {\n",
    "    \"index_defaults\": {\n",
    "        \"treat_urls_and_pointers_as_images\": True,\n",
    "        \"image_preprocessing\": {\n",
    "            \"patch_method\": \"frcnn\"\n",
    "        },\n",
    "        \"model\":\"ViT-B/16\",\n",
    "        \"normalize_embeddings\":True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e86ba0-9dba-4ce2-860c-9afb1f68b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31dd47-54d9-468f-97ed-53d2bebd94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"stable-diffusion-open-prompts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9412e2-42fb-4ef1-a153-2eecce03ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mq.create_index(index_name, settings_dict=marqo_settings)\n",
    "    print(\"Risen from nothing, it wishes to learn\")\n",
    "except:\n",
    "    mq.index(index_name).delete()\n",
    "    mq.create_index(index_name, settings_dict=marqo_settings)\n",
    "    print(\"It has been killed and brought back anew sire. Thirsty for knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6af00-fe66-465d-8045-b78e09253021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1345d-521e-491d-a84f-adb12a0289b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == \"cuda\":\n",
    "    NUM_PROCS = torch.cuda.device_count()\n",
    "else:\n",
    "    NUM_PROCS = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2eb2fe-ab6e-448d-929c-c938dbf311a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1000\n",
    "batch_size = data_shape//num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32394a81-958f-4f15-9249-5410154a457a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we use parallel indexing to speed up the task\n",
    "responses = mq.index(index_name).add_documents(data, device=device, processes=NUM_PROCS, batch_size=batch_size)\n",
    "# for data_doc in tqdm(data):\n",
    "#     try:\n",
    "#         responses = mq.index(index_name).add_documents([data_doc], device=device)\n",
    "#         # print(f\"<SUCCESS>\\nAdded prompt:\\n{data_doc['prompt']}\\nURI: {data_doc['local_image_location']}\\n\")\n",
    "#     except:\n",
    "#         print(f\"<FAILURE>\\nSkipping prompt:\\n{data_doc['prompt']}\\nURI: {data_doc['local_image_location']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80332b8-3fbb-4bbc-aad7-10eee9582f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Split into two notebooks\n",
    "# First is half of this -> prep data for insertion\n",
    "# That includes the transforms done here\n",
    "# instead of ignoring the problematic opened images, let us pre-download all the images and place it alongside tha appropriate dataset\n",
    "#     and have the image location be the name of the file where it will prepended with the artifact location after downlaoded\n",
    "# If it is rate limit add some logic to check the files in an artifact against the table of downloaded files already\n",
    "# and download that which was not downloaded and relog with that which was alrewady logged?\n",
    "# Second will be the insertion which will simply pull the appropriate data down and log"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
