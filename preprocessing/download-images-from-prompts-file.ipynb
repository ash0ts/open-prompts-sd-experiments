{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5b841-33d3-48a1-b6a3-1b492d35fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U wandb\n",
    "!pip install -U pandas # upgrade pandas\n",
    "!pip install -U pandarallel\n",
    "# !pip install -U dask[\"complete\"]\n",
    "# !pip install swifter # first time installation\n",
    "# !pip install swifter[groupby]\n",
    "# !pip install wrapt_timeout_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d28ef0-73d5-47e7-b634-843b6357408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0da344-cbd9-4cd0-9b50-342891e28f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"krea-open-prompts\"\n",
    "run_name = \"download-open-prompts-sd-images\"\n",
    "tags = [\"download\", \"stable_diffusion\", \"images\"]\n",
    "_config = {\n",
    "    # option of \"prompts\" or \"sample_prompts\"\n",
    "    \"dataset\": \"prompts\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa9e30-bb60-4eed-9707-7bac2f9b5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=project_name, name=run_name, tags=tags, config=_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa578f0d-4efe-4142-be52-fb87094066a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = run.config\n",
    "dataset_name = config['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5063d-4386-47cc-8a26-822c53100722",
   "metadata": {},
   "outputs": [],
   "source": [
    "art = run.use_artifact('open-prompts-sd:latest', type='raw_data')\n",
    "dataset_path = art.get_path(f\"{dataset_name}.csv\").download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c2cdf-71cb-4e8c-854c-bbab51ff98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.init(ignore_reinit_error=True, dashboard_host=\"0.0.0.0\", include_dashboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f10393-8929-4fca-bdb7-945845b8bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "# By default, Pandarallel use all available CPUs\n",
    "NB_PHYSICAL_CORES = psutil.cpu_count(logical=False)\n",
    "NB_CORES = psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b03f8-49df-4e63-b091-45e1eceabe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cbda5-d988-4b97-80dd-118b27ba59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "#LEts see if using logical cores too will be good\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=NB_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2f5ba-ea67-45b0-937c-722d213a61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import swifter\n",
    "# import modin.pandas as mpd\n",
    "# from modin.config import ProgressBar\n",
    "# ProgressBar.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bced7c-1035-4598-bf18-97866e2e89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffd2ad-b06e-41a8-855a-0f7fead087d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c94a4a-95f7-407b-852e-b8b5b9eef6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_flatten_json(record):\n",
    "    json_record = json.loads(record)\n",
    "    flattened_json_record = json_normalize(json_record, sep=\"_\")\n",
    "    return flattened_json_record.to_dict(orient=\"records\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cc570-d3c1-456e-8fa3-318b0c82f4ac",
   "metadata": {},
   "source": [
    "After trial and error:\n",
    "If you want high perofrmance applies and processing of dataframes in an easy manner\n",
    "Start with pandarallel (https://nalepae.github.io/pandarallel/user_guide/). \n",
    "pandarallel gets around this limitation by using all cores of your computer. But, in return, pandarallel need twice the memory that standard pandas operation would normally use.\n",
    "\n",
    "==> pandarallel should NOT be used if your data cannot fit into memory with pandas itself\n",
    "Then try swifter. It will try to automagically figure out if your function is vectorized, dask apply ready, and then defaults to pandas\n",
    "Hard to get the function just right because i am dumb. force_parallel is nice. Felt faster but not the speeds I wanted to see like with throwing all cores at the problem\n",
    "If still nothing then use raw modin or dask\n",
    "You really need to make sure your function will apply really well on the partitions and may need to worry about data transfer but honestly not that bad. You need to load the dataframe differently than pandas so kind of not as automagic\n",
    "Anything more and you probs need spark which i did not try becuase i have 0 desire for a quick and dirty clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc39018-06e6-4034-a021-9da2d3e3e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6053976-b460-4b0d-9cc6-3954b427c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb295cf3-bc79-4d16-8e4b-e6f58ee92a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7b082-d5c7-4a4f-a7bb-235b080b42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"test_modin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82cdf8-488b-4574-b997-a634cf10b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = Path(\".\", dataset_name)\n",
    "image_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184c71c-966f-4628-ba81-e84e7af88d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_timeout = 1\n",
    "long_sleep = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70edad2-e2b8-4002-a4ac-bc48bd58558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from requests.exceptions import Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d71800-408f-4f1a-bc8e-100b4d4ac3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_local_file_path(image_url):\n",
    "    file_name = image_url.rsplit('/', 1)[-1]\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a512e-6005-45ae-9902-e3e0fff1f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image_files(row):\n",
    "    image_url = row[\"raw_discord_data_image_uri\"]\n",
    "    file_path = Path(image_folder, row[\"local_image_location\"])\n",
    "    try:\n",
    "        #Allows for retries without redownloads\n",
    "        if file_path.exists():\n",
    "            #Test the image actually opens and then close it\n",
    "            img = Image.open(file_path)\n",
    "            img.close()\n",
    "            return True\n",
    "        #Need to sleep so we dont explode discord and get banned lmao\n",
    "        # could actually add logic in the try catch to sleep or somehting\n",
    "        # time.sleep(0.2)\n",
    "        #Downloads image and writes it to file\n",
    "        img_data = requests.get(image_url, timeout=default_timeout).content\n",
    "        with open(file_path, 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "        #Test the image actually opens and then close it\n",
    "        img = Image.open(file_path)\n",
    "        img.close()\n",
    "        return True\n",
    "    except Timeout:\n",
    "        print(\"sleeping zzz\")\n",
    "        time.sleep(long_sleep)\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        #Remove traces of erred files to prevent broken files from still existing\n",
    "        if file_path.exists():\n",
    "            os.remove(file_path)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd13cf4-047c-4225-8661-4b2c82b6fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8b100-76f8-42f1-b7c7-0dd432290d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUG: check if modin actually helps here\n",
    "# df = mpd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aedcb4-fd93-4bb4-b974-22baa15855c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b784d-25b2-499c-83c1-0607dc0286e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#TODO: store images in a bucket and read/write to there and make the artifact reference that. Will allow for multiple pcs and processes to write to it\n",
    "#also not restricted to local filestore\n",
    "downloaded_images = set(os.listdir(image_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6f046-9a57-4d99-8aa0-adbaf6245778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add distributed machine setup with prechunked dataframes where the flag is which chunk to process. Write to S3 and read from S3. Spin up a bunch of machines andrun this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755d203-de5b-497a-9da9-eff68b56246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(downloaded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afc1ae-b3c8-4639-b0ae-47c6bbb3fced",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "chunksize = 50000\n",
    "responses = []\n",
    "for raw_df in pd.read_csv(dataset_path, chunksize=chunksize):\n",
    "    df = pd.DataFrame(raw_df[\"raw_data\"].parallel_apply(load_and_flatten_json).to_list())\n",
    "    # df = pd.DataFrame(raw_df[\"raw_data\"].swifter.force_parallel().apply(load_and_flatten_json).to_list())\n",
    "\n",
    "    df[\"local_image_location\"] = df[\"raw_discord_data_image_uri\"].str.rsplit(\"/\", 1).str[-1]\n",
    "    df[\"prompt\"] = raw_df[\"prompt\"]\n",
    "    del raw_df\n",
    "    gc.collect()\n",
    "    # for chunk in np.array_split(df, 10):\n",
    "        # responses = chunk[\"raw_discord_data_image_uri\"].parallel_apply(download_image_files)\n",
    "    df_to_download = df[~df[\"local_image_location\"].isin(downloaded_images)][[\"raw_discord_data_image_uri\", \"local_image_location\"]]\n",
    "    if df_to_download.shape[0] == 0:\n",
    "        continue\n",
    "    try:\n",
    "        response = df_to_download[[\"raw_discord_data_image_uri\", \"local_image_location\"]].parallel_apply(download_image_files, axis=1)\n",
    "        responses.append(response)\n",
    "    except:\n",
    "        continue\n",
    "    # responses = df[\"raw_discord_data_image_uri\"].swifter.force_parallel().apply(download_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0ae1a-26f6-41b9-a200-53eba63f4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
